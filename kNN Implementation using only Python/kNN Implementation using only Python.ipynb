{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Implementing kNN (k-Nearest Neighbors Algorithm) using only Python.\n",
    "dataset: https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival\n",
    "\n",
    "Dataset Description: The dataset contains cases from a study that was conducted\n",
    "                     between 1958 and 1970 at the University of Chicago's Billings\n",
    "                     Hospital on the survival of patients who had undergone surgery\n",
    "                     for breast cancer.\n",
    "\n",
    "Dataset Attributes Description: 1. Age of patient at time of operation (numerical)\n",
    "                                2. Patient's year of operation (year - 1900, numerical)\n",
    "                                3. Number of positive axillary nodes detected (numerical)\n",
    "                                4. Survival status (class attribute)\n",
    "                                     1 = the patient survived 5 years or longer\n",
    "                                     2 = the patient died within 5 year\n",
    "'''\n",
    "\n",
    "# sample list\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open dataset (.data file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/haberman.data', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        attributes = line.replace('\\n', '').split(',')\n",
    "        # converting items from the list of attributes (string to integer)\n",
    "        samples.append([int(attribute) for attribute in attributes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Return and Displaying informations about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_info(samples, verbose=True):\n",
    "    # Displaying number of samples\n",
    "    if verbose:\n",
    "        print(\"Number of samples: {}\".format(len(samples)))\n",
    "    \n",
    "    # initializing the counting variables for each label\n",
    "    label_1, label_2 = 0, 0\n",
    "    for sample in samples:\n",
    "        if sample[-1] == 1:\n",
    "            label_1 += 1\n",
    "        else:\n",
    "            label_2 += 1\n",
    "    \n",
    "    # displaying the number of samples of each label\n",
    "    if verbose:\n",
    "        print('Number of Samples of Label 1: {}'.format(label_1))\n",
    "        print('Number of Samples of Label 2: {}'.format(label_2))\n",
    "    \n",
    "    # return a tuple with the number of samples and the number of samples of each label\n",
    "    return len(samples), label_1, label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 306\n",
      "Number of Samples of Label 1: 225\n",
      "Number of Samples of Label 2: 81\n"
     ]
    }
   ],
   "source": [
    "# unpacking return tuple of dataset_info function\n",
    "_, label_1, label_2 = dataset_info(samples, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of the dataset to include in the train split (60%)\n",
    "p = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the test and training samples list\n",
    "train, test = [], []\n",
    "\n",
    "# Calculating the maximum amount of training samples per label\n",
    "max_label_1, max_label_2 = int(p * label_1), int(p * label_2)\n",
    "\n",
    "# Total amount of training samples\n",
    "total_of_train_samples = max_label_1 + max_label_2\n",
    "\n",
    "# Initializing labels counters\n",
    "count_label_1, count_label_2 = 0, 0\n",
    "\n",
    "for sample in samples:\n",
    "    # If the sum of the counters is less than the total amount of training samples\n",
    "    if (count_label_1 + count_label_2) < (total_of_train_samples):\n",
    "        # Adding sample to training set\n",
    "        train.append(sample)\n",
    "        if (sample[-1] == 1) and (count_label_1 < max_label_1):\n",
    "            count_label_1 += 1\n",
    "        else:\n",
    "            count_label_2 += 1\n",
    "    else:\n",
    "        # Adding sample to list of test set\n",
    "        test.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Train Samples\n",
      "Number of samples: 183\n",
      "Number of Samples of Label 1: 132\n",
      "Number of Samples of Label 2: 51\n",
      "----------------------------------\n",
      "Test Samples\n",
      "Number of samples: 123\n",
      "Number of Samples of Label 1: 93\n",
      "Number of Samples of Label 2: 30\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about test and training samples\n",
    "print('----------------------------------')\n",
    "print('Train Samples')\n",
    "dataset_info(train)\n",
    "print('----------------------------------')\n",
    "print('Test Samples')\n",
    "dataset_info(test)\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidian_distance(v1, v2):\n",
    "    # Getting vector 1 size and initializing summing variable \n",
    "    length, summation = len(v1), 0\n",
    "\n",
    "    # Adding the square of the difference of the values of the two vectors\n",
    "    for i in range(length - 1):\n",
    "        # Adding the square of the difference of the values of the two vectors\n",
    "        summation += math.pow(v1[i] - v2[i], 2)\n",
    "\n",
    "    # Returning the square root of the sum\n",
    "    return math.sqrt(summation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing euclidian_distance function\n",
    "v1 = [1, 2, 3]\n",
    "v2 = [2, 1, 5]\n",
    "euclidian_distance(v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train, new_sample, K):\n",
    "    # Initializing dict of distances and variable with size of training set\n",
    "    distances, train_length = {}, len(train)\n",
    "\n",
    "    # Calculating the Euclidean distance between the new\n",
    "    # sample and the values of the training sample\n",
    "    for i in range(train_length):\n",
    "        d = euclidian_distance(train[i], new_sample)\n",
    "        distances[i] = d\n",
    "    \n",
    "    # Selecting the K nearest neighbors\n",
    "    k_neighbors = sorted(distances, key=distances.get)[:]\n",
    "    \n",
    "    # Initializing labels counters\n",
    "    label_1, label_2 = 0, 0\n",
    "    for index in k_neighbors:\n",
    "        if train[index][-1] == 1:\n",
    "            label_1 += 1\n",
    "        else:\n",
    "            label_2 += 1\n",
    "    if label_1 > label_2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New sample \n",
      "[56, 67, 0, 1]\n",
      "Label: 1\n",
      "---------------------------\n",
      "kNN return \n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "# Testing kNN function\n",
    "print(\"New sample \\n{}\".format(test[12]))\n",
    "print(\"Label: %d\" %(test[12][3]))\n",
    "print('---------------------------')\n",
    "print(\"kNN return \")\n",
    "print('Label: {}'.format(knn(train, test[12], K=13)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing kNN and Displaying the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 183\n",
      "Number of test samples: 123\n",
      "Total of hits: 93\n",
      "Number of hits (Percentage): 75.61%\n"
     ]
    }
   ],
   "source": [
    "# Initializing hit counter\n",
    "hit_counter = 0\n",
    "# Performing kNN on all test samples\n",
    "for sample in test:\n",
    "    label = knn(train, sample, K=13)\n",
    "    # Comparing method result with actual sample result\n",
    "    if sample[-1] == label:\n",
    "        hit_counter += 1\n",
    "        \n",
    "print('Number of train samples: %d' % len(train))\n",
    "print('Number of test samples: %d' % len(test))\n",
    "print('Total of hits: %d' % hit_counter)\n",
    "print('Number of hits (Percentage): %.2f%%' % (100 * hit_counter / len(test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
